{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"cloudevents-pydantic","text":"<p>This is an implementation of the CloudEvents spec using Pydantic V2 for high performance during validation and serialization.</p> <p>It is meant to support natively FastAPI and FastStream (WIP)</p>"},{"location":"#how-to-use","title":"How to use","text":"<pre><code>pip install cloudevents-pydantic\n</code></pre> <pre><code>from cloudevents_pydantic.bindings.http import HTTPHandler\nfrom cloudevents_pydantic.events import CloudEvent\n\nhandler = HTTPHandler()\nminimal_attributes = {\n    \"type\": \"com.example.string\",\n    \"source\": \"https://example.com/event-producer\",\n}\n\n# `CloudEvent` is a Pydantic model to handle validation and serialization\n# `event_factory` is a helper method to autogenerate some of the mandatory \n# such as id, time, specversion\nevent = CloudEvent.event_factory(**minimal_attributes)\n\n# Single event HTTP serialization\nheaders, single_event_as_json = handler.to_json(event)\n\n# Batch of events HTTP serialization\nheaders, batch_of_events_as_json = handler.to_json_batch([event])\n\n# Parsing a JSON string for a single event\nparsed_event = handler.from_json(single_event_as_json)\n\n# Parsing a JSON string for a single event\nparsed_event_list = handler.from_json(batch_of_events_as_json)\n</code></pre> <p>Refer to the docs for more advanced use cases and for details on how to create custom events.</p>"},{"location":"#performance","title":"Performance","text":"<p>Using pydantic gives a great performance boost if compared to the official SDK. (there's obviously some performance issue in the official serialization using pydantic)</p> <p>These results come from a Macbook Pro M4 Pro on python 3.13. Feel free to run the <code>benchmark.py</code> script yourself.</p> <pre><code>==== 1M iterations benchmark ====\nTimings for HTTP JSON deserialization:\nThis package: 2.3955996250006137\nOfficial SDK using pydantic model: 11.389213957998436\nOfficial SDK using http model: 10.174893917006557\n\nTimings for HTTP JSON serialization:\nThis package: 3.497491959002218\nOfficial SDK using pydantic model: 31.92037604199868\nOfficial SDK using http model: 6.780242209002608\n</code></pre>"},{"location":"#supported-specification-features","title":"Supported specification features","text":"Core Specification v1.0 CloudEvents Core \u2705 Event Formats v1.0 AVRO Event Format \u274c JSON Event Format \u2705 Protocol Bindings v1.0 HTTP Protocol Binding \u2705 Kafka Protocol Binding \u274c Content Modes v1.0 HTTP Binary \u2705 HTTP Structured \u2705 HTTP Batch \u2705 Kafka Binary \u274c Kafka Structured \u274c Kafka Batch \u274c"},{"location":"#commands-for-development","title":"Commands for development","text":"<p>All the common commands used during development can be run using make targets:</p> <ul> <li><code>make dev-dependencies</code>: Install dev requirements</li> <li><code>make update-dependencies</code>: Update dev requirements</li> <li><code>make fix</code>: Run code style and lint automatic fixes (where possible)</li> <li><code>make test</code>: Run test suite against system python version</li> <li><code>make check</code>: Run tests against all available python versions, code style and lint checks</li> <li><code>make type</code>, <code>make format</code>, <code>make lint</code>, <code>make bandit</code>: Run the relevant check</li> <li><code>make docs</code>: Render the mkdocs website locally</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>The package is structured following the same structure as CloudEvents spec in the following modules:</p> <ul> <li><code>events</code> implements the base <code>CloudEvent</code> model, required fields and canonical data types serialization.</li> <li><code>formats</code> implements the logic for serialization and deserialization between the <code>CloudEvent</code> model   and formats (JSON,   AVRO, etc.). These are   not usually used directly.</li> <li><code>bindings</code> implements the logic for serialization and deserialization between the <code>CloudEvent</code> model   and protocol bindings (HTTP, KAFKA, etc.). It reuses functions from <code>formats</code> when necessary (i.e. HTTP in   structured JSON mode   will use the already implemented JSON format)</li> </ul>"},{"location":"event_class/","title":"Event class","text":""},{"location":"event_class/#the-cloudevent-class-and-the-pydantic-typeadapter","title":"The CloudEvent class and the pydantic TypeAdapter","text":"<p>The <code>CloudEvent</code> class is the core of the system using a Pydantic model. It is responsible for all the validation and serialization of the canonic types.</p> <p>The class has some basic support for <code>data</code> which has the <code>Any</code> type. Pydantic will use a best effort approach for the serialization process and no validation.</p> <p>You will usually use the <code>CloudEvent</code> class (or a subclass) it when\\ creating an event from your application domain logic.</p> <p>Use subclasses</p> <p>It is recommended to create subclasses with your specific data types so you can better control the serialization rules.</p> <p>You can create an event in different ways:</p> Factory method (recommended)Class constructor <p>The class provides a nice factory method that takes care of providing some default values for required fields.</p> <pre><code>from cloudevents_pydantic.events import CloudEvent\n\n# `source` and `type` are the minimal needed attributes when using the factory\nattributes = {\n    \"source\": \"order:service\",\n    \"type\": \"order.created\",\n}\n\nmy_event = CloudEvent.event_factory(**attributes)\n</code></pre> <p>The provided defaults are:</p> <ul> <li><code>id</code>: Uses ULID (a sortable version of UUID)</li> <li><code>time</code>: Simple <code>datetime.now()</code> in UTC timezone</li> <li><code>specversion</code>: Hardcoded <code>1.0</code> (the only supported version for now)</li> </ul> <p>Default values and the factory</p> <p>We don't define defaults in the <code>CloudEvent</code> class for the mandatory fields. In this way we can validate their presence when we receive an event from an external source.</p> <p>Do not override the model fields defaults when subclassing the <code>CloudEvent</code> class. Override the <code>event_factory</code> as needed.</p> <p>Use the constructor from the model</p> <pre><code>from cloudevents_pydantic.events import CloudEvent\nimport datetime\n\n# Full set of attributes\nattributes = {\n    \"data\": {\"data-key\": \"val\"},\n    \"datacontenttype\": \"application/octet-stream\",\n    \"dataschema\": \"http://some-dataschema.url\",\n    \"id\": \"id-can-be-anything\",\n    \"source\": \"dummy:source\",\n    \"specversion\": \"1.0\",\n    \"subject\": \"some-subject\",\n    \"time\": datetime.datetime(\n            year=2020,\n            month=7,\n            day=16,\n            hour=12,\n            minute=3,\n            second=20,\n            microsecond=519216,\n            tzinfo=datetime.timezone(datetime.timedelta(hours=4)),\n    ),\n    \"type\": \"dummy.type\",\n}\n\nmy_event = CloudEvent(**attributes)\n</code></pre> <p>Default values and the factory</p> <p>You can use either <code>str</code> values or python objects (see the <code>time</code> field)</p>"},{"location":"event_class/#best-practices-when-creating-your-event-classes","title":"Best practices when creating your event classes","text":"<p>When you create event types in your app you will want to make sure to follow these best practices:</p> <ul> <li>Use <code>TypedDict</code> for structured data instead of nested pydantic models (as specified in   Pydantic performance   documentatin)</li> <li>Use the fields types defined in the <code>cloudevents_pydantic.events.field.types</code>. These types will   be kept up to date and make sure their validation, serialization and deserialization rules   will be compliant with the CloudEvents spec.</li> <li>Write your own pydantic <code>Field</code> for data</li> <li>Use the fields available in the <code>cloudevents_pydantic.events.field.metadata</code> when overriding   the cloudevent fields to inherit CloudEvents field descriptive metadata (i.e. title, description)   will be populated in the schema.</li> </ul> <p>Example:</p> <pre><code>from typing import Annotated, Literal, TypedDict\n\nfrom pydantic import Field\n\nfrom cloudevents_pydantic.events import CloudEvent\nfrom cloudevents_pydantic.events.fields import metadata, types\n\n\nclass OrderCreatedData(TypedDict):\n    a_str: types.String\n    an_int: types.Integer\n\n\nOrderCreatedDataField = Field(\n    title=\"An order representation\",\n    description=\"A nice new order has been created! OMG!\",\n    examples=[\"{'a_str': 'a nice string', 'an_int': 1}\"],\n)\n\n\nclass OrderCreated(CloudEvent):\n    data: Annotated[OrderCreatedData, OrderCreatedDataField]\n    type: Annotated[\n        Literal[\"order_created\"], Field(default=\"order_created\"), metadata.FieldType\n    ]\n    source: Annotated[\n        Literal[\"order_service\"], Field(default=\"order_service\"), metadata.FieldSource\n    ]\n</code></pre> <p>Use subclasses</p> <p>Be careful when overriding attributes for the <code>CloudEvent</code> fields, except for <code>data</code>, you'll probably only need to override <code>type</code> and <code>source</code>.</p>"},{"location":"protocol_bindings/http_binding/","title":"HTTP binding","text":"<p>Using the HTTP binding handler is straightforward. Just remember to reuse the same <code>HTTPHandler</code> multiple times.</p> \u2705 Good\u274c Bad <pre><code>from cloudevents_pydantic.events import CloudEvent\nfrom cloudevents_pydantic.bindings.http import HTTPHandler\n\nclass OrderCreated(CloudEvent):\n    ...\n\nhttp_handler = HTTPHandler(OrderCreated)\n\ndef do_something():\n    http_handler.from_json(\"json_body\")\n</code></pre> <pre><code>from cloudevents_pydantic.events import CloudEvent\nfrom cloudevents_pydantic.bindings.http import HTTPHandler\n\nclass OrderCreated(CloudEvent):\n    ...\n\ndef do_something():\n    http_handler = HTTPHandler(OrderCreated)\n    http_handler.from_json(\"json_body\")\n</code></pre> <p>Why you have to reuse the same object?</p> <p>When the HTTPHandler instance is created it creates internally instances of Pydantic <code>TypeAdapter</code> for the event class, to handle efficiently event serialization and discriminated unions. This is an expensive operation. Check the Pydantic documentation about this.</p>"},{"location":"protocol_bindings/http_binding/#deserialize-an-event","title":"Deserialize an event","text":"<p>HTTP deserialization parses the body to reconstruct the event.</p> Custom Event classCloudEvent class <pre><code>from cloudevents_pydantic.events import CloudEvent\nfrom cloudevents_pydantic.bindings.http import HTTPHandler\n\nclass OrderCreated(CloudEvent):\n    ...\n\nsingle_event_json = '{\"data\":null,\"source\":\"https://example.com/event-producer\",\"id\":\"b96267e2-87be-4f7a-b87c-82f64360d954\",\"type\":\"com.example.string\",\"specversion\":\"1.0\",\"time\":\"2022-07-16T12:03:20.519216+04:00\",\"subject\":null,\"datacontenttype\":null,\"dataschema\":null}'\nbatch_event_json = '[{\"data\":null,\"source\":\"https://example.com/event-producer\",\"id\":\"b96267e2-87be-4f7a-b87c-82f64360d954\",\"type\":\"com.example.string\",\"specversion\":\"1.0\",\"time\":\"2022-07-16T12:03:20.519216+04:00\",\"subject\":null,\"datacontenttype\":null,\"dataschema\":null}]'\n\nhttp_handler = HTTPHandler(OrderCreated)\n\n# Single JSON event\nevent = http_handler.from_json(single_event_json)\n# JSON batch (list) of events\nbatch_of_events = http_handler.from_json_batch(batch_event_json)\n# HTTP Binary event (using the raw request headers and body)\nevent = http_handler.from_binary(headers={}, body=\"body\")\n</code></pre> <pre><code>from cloudevents_pydantic.bindings.http import HTTPHandler\n\nsingle_event_json = '{\"data\":null,\"source\":\"https://example.com/event-producer\",\"id\":\"b96267e2-87be-4f7a-b87c-82f64360d954\",\"type\":\"com.example.string\",\"specversion\":\"1.0\",\"time\":\"2022-07-16T12:03:20.519216+04:00\",\"subject\":null,\"datacontenttype\":null,\"dataschema\":null}'\nbatch_event_json = '[{\"data\":null,\"source\":\"https://example.com/event-producer\",\"id\":\"b96267e2-87be-4f7a-b87c-82f64360d954\",\"type\":\"com.example.string\",\"specversion\":\"1.0\",\"time\":\"2022-07-16T12:03:20.519216+04:00\",\"subject\":null,\"datacontenttype\":null,\"dataschema\":null}]'\n\nhttp_handler = HTTPHandler()\n\n# Single JSON event\nevent = http_handler.from_json(single_event_json)\n# JSON batch (list) of events\nbatch_of_events = http_handler.from_json_batch(batch_event_json)\n# HTTP Binary event (using the raw request headers and body)\nevent = http_handler.from_binary(headers={}, body=\"body\")\n</code></pre> Use discriminated Unions to handle multiple Event classes <p>You'll want to use discriminated unions as event class and use a single <code>HTTPHandler</code> for multiple Event classes to be more efficient on validation and to produce a correct schema. </p> <pre><code>from typing import Annotated, Literal, Union\n\nfrom pydantic import Field\nfrom typing_extensions import TypedDict\n\nfrom cloudevents_pydantic.bindings.http import HTTPHandler\nfrom cloudevents_pydantic.events import CloudEvent\n\n\nclass OrderCreatedEvent(CloudEvent):\n    data: TypedDict(\"OrderCreatedData\", {\"order_id\": str})\n    type: Literal[\"order_created\"]\n\n\nclass CustomerCreatedEvent(CloudEvent):\n    data: TypedDict(\"CustomerCreatedData\", {\"customer_id\": str})\n    type: Literal[\"customer_created\"]\n\n\nEvent = Annotated[\n    Union[OrderCreatedEvent, CustomerCreatedEvent],\n    Field(discriminator=\"type\"),\n]\n\nhttp_handler = HTTPHandler(Event)\n\ncustomer_event_json = '{\"data\":{\"customer_id\":\"123\"},\"source\":\"customer_service\",\"id\":\"123\",\"type\":\"customer_created\",\"specversion\":\"1.0\",\"time\":null,\"subject\":null,\"datacontenttype\":null,\"dataschema\":null}'\n\nprint(type(http_handler.from_json(customer_event_json)))\n# &lt;class '__main__.CustomerCreatedEvent'&gt;\n</code></pre>"},{"location":"protocol_bindings/http_binding/#fastapi","title":"FastAPI","text":"<p>Both this package and FastAPI are built on top of Pydantic. This means you don't need to instantiate a <code>HTTPHandler</code> to receive CloudEvents using a FastAPI endpoint.</p> <pre><code>### Event classes omitted ###\n\nEvent = Annotated[\n    Union[OrderCreatedEvent, CustomerCreatedEvent],\n    Field(discriminator=\"type\"),\n]\n\n# Endpoint for single events\n@router.post(\"/event\", status_code=204)\nasync def submit_event(\n    event: Annotated[Event, Body()],\n    content_type: Annotated[\n        Literal[\"application/cloudevents+json; charset=UTF-8\"], Header()\n    ],\n) -&gt; None:\n    do_something(event)\n\n# Endpoint for event batches\n@router.post(\"/batch\", status_code=204)\nasync def submit_event_batch(\n    event_batch: Annotated[List[Event], Body()],\n    content_type: Annotated[\n        Literal[\"application/cloudevents-batch+json; charset=UTF-8\"], Header()\n    ],\n) -&gt; None:\n    for event in event_batch:\n        do_something(event)\n</code></pre> <p>Generate the OpenAPI schema correctly</p> <p>In order to have the OpenAPI spec correctly generated by FastAPI you'll need to work around some FastAPI limitations and manually specify some of the needed data. You can find a detailed example here.</p>"},{"location":"protocol_bindings/http_binding/#serialize-an-event","title":"Serialize an event","text":"<p>HTTP serialization returns header and body to be used in a HTTP request.</p> Custom Event classCloudEvent class <pre><code>from cloudevents_pydantic.events import CloudEvent\nfrom cloudevents_pydantic.bindings.http import HTTPHandler\n\nclass OrderCreated(CloudEvent):\n    ...\n\nminimal_attributes = {\n    \"type\": \"order_created\",\n    \"source\": \"https://example.com/event-producer\",\n    \"id\": \"b96267e2-87be-4f7a-b87c-82f64360d954\",\n    \"specversion\": \"1.0\",\n}\n\nhttp_handler = HTTPHandler(OrderCreated)\nevent = OrderCreated.event_factory(**minimal_attributes)\n\n# Single event\nheaders, body = http_handler.to_json(event)\n# Batch (list) of events\nheaders, body = http_handler.to_json_batch([event])\n# HTTP Binary event\nheaders, body = http_handler.to_json(event)\n</code></pre> <pre><code>from cloudevents_pydantic.events import CloudEvent\nfrom cloudevents_pydantic.bindings.http import HTTPHandler\n\nminimal_attributes = {\n    \"type\": \"order_created\",\n    \"source\": \"https://example.com/event-producer\",\n    \"id\": \"b96267e2-87be-4f7a-b87c-82f64360d954\",\n    \"specversion\": \"1.0\",\n}\n\nhttp_handler = HTTPHandler()\nevent = CloudEvent.event_factory(**minimal_attributes)\n\n# Single event\nheaders, body = http_handler.to_json(event)\n# Batch (list) of events\nheaders, body = http_handler.to_json_batch([event])\n# HTTP Binary event\nheaders, body = http_handler.to_json(event)\n</code></pre>"}]}